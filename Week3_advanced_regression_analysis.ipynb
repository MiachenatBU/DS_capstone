{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "# Advanced Regression Techniques for CVD Healthcare Cost Analysis\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "This notebook explores advanced regression techniques to analyze the data. Including:\n",
                "1. Linear Regression with Forward and Backward Feature Selection.\n",
                "2. Principal Component Regression (PCR).\n",
                "3. Partial Least Squares Regression (PLSR).\n",
                "    \n",
                "These methods will help in continuing identifying the most significant predictors of healthcare costs and in building more robust predictive models. We will use the rank of healthcare costs as our target variable, as it has proven to be more suitable for linear models in our previous analyses.\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## 1. Data Loading and Preparation\n",
                "Load the data, select relevant features, handle missing values, and scale the data.\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import pandas as pd\n",
                "import statsmodels.api as sm\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.cross_decomposition import PLSRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.metrics import r2_score\n",
                "    \n",
                "# Load the dataset\n",
                "df = pd.read_csv('CVD_data2.csv')\n",
                "    \n",
                "# Select a broader set of predictors for feature selection\n",
                "features = ['AGEY1X', 'ADSEX4', 'PRVEVY1', 'DIABDXY1_M18', 'ANGIDXY1', 'ARTHDXY1', 'CHDDXY1', 'MIDXY1', 'total_comorbidities']\n",
                "target = 'TOTTCHY1_rank'\n",
                "    \n",
                "df_model = df[features + [target]].dropna()\n",
                "    \n",
                "# Binarize categorical predictors (assuming 1 is 'Yes' and 2 is 'No')\n",
                "for col in ['ADSEX4', 'PRVEVY1', 'DIABDXY1_M18', 'ANGIDXY1', 'ARTHDXY1', 'CHDDXY1', 'MIDXY1']:\n",
                "    df_model[col] = df_model[col].apply(lambda x: 1 if x == 1 else 0)\n",
                "    \n",
                "# Define X and y\n",
                "X = df_model[features]\n",
                "y = df_model[target]\n",
                "    \n",
                "# Scale the features\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## 2. Feature Selection\n",
                "We will implement forward and backward selection to identify the most significant predictors for our linear regression model. We will use the p-value from the `statsmodels` library as our selection criterion.\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Selected features (Forward Selection): ['total_comorbidities', 'AGEY1X', 'ADSEX4', 'PRVEVY1', 'ARTHDXY1']\n",
                        "                            OLS Regression Results                            \n",
                        "==============================================================================\n",
                        "Dep. Variable:          TOTTCHY1_rank   R-squared:                       0.194\n",
                        "Model:                            OLS   Adj. R-squared:                  0.193\n",
                        "Method:                 Least Squares   F-statistic:                     167.9\n",
                        "Date:                Mon, 20 Oct 2025   Prob (F-statistic):          2.16e-160\n",
                        "Time:                        00:24:59   Log-Likelihood:                -30853.\n",
                        "No. Observations:                3487   AIC:                         6.172e+04\n",
                        "Df Residuals:                    3481   BIC:                         6.175e+04\n",
                        "Df Model:                           5                                         \n",
                        "Covariance Type:            nonrobust                                         \n",
                        "=======================================================================================\n",
                        "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "---------------------------------------------------------------------------------------\n",
                        "const                3721.3127     28.545    130.366      0.000    3665.346    3777.280\n",
                        "total_comorbidities   332.0147     41.423      8.015      0.000     250.798     413.231\n",
                        "AGEY1X                416.5722     33.242     12.532      0.000     351.397     481.748\n",
                        "ADSEX4               -253.3299     28.903     -8.765      0.000    -309.999    -196.661\n",
                        "PRVEVY1               149.6013     29.423      5.085      0.000      91.913     207.289\n",
                        "ARTHDXY1              208.6796     41.413      5.039      0.000     127.483     289.877\n",
                        "==============================================================================\n",
                        "Omnibus:                      190.410   Durbin-Watson:                   1.863\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.498\n",
                        "Skew:                          -0.152   Prob(JB):                     7.39e-19\n",
                        "Kurtosis:                       2.306   Cond. No.                         2.75\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "def forward_selection(X, y, significance_level=0.05):\n",
                "    initial_features = X.columns.tolist()\n",
                "    best_features = []\n",
                "    \n",
                "    while True:\n",
                "        remaining_features = list(set(initial_features) - set(best_features))\n",
                "        new_pval = pd.Series(index=remaining_features, dtype=float)\n",
                "        \n",
                "        for new_column in remaining_features:\n",
                "            model = sm.OLS(y, sm.add_constant(X[best_features + [new_column]])).fit()\n",
                "            new_pval[new_column] = model.pvalues[new_column]\n",
                "        \n",
                "        min_p_value = new_pval.min()\n",
                "        if min_p_value < significance_level:\n",
                "            best_features.append(new_pval.idxmin())\n",
                "        else:\n",
                "            break\n",
                "    \n",
                "    return best_features\n",
                "\n",
                "X_scaled = X_scaled.reset_index(drop=True)\n",
                "y = y.reset_index(drop=True)\n",
                "# Run forward selection\n",
                "forward_features = forward_selection(X_scaled, y)\n",
                "print(\"Selected features (Forward Selection):\", forward_features)\n",
                "\n",
                "# Fit final model\n",
                "model_forward = sm.OLS(y, sm.add_constant(X_scaled[forward_features])).fit()\n",
                "print(model_forward.summary())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Selected features (Backward Elimination): ['AGEY1X', 'ADSEX4', 'PRVEVY1', 'DIABDXY1_M18', 'ARTHDXY1', 'CHDDXY1', 'MIDXY1']\n",
                        "                            OLS Regression Results                            \n",
                        "==============================================================================\n",
                        "Dep. Variable:          TOTTCHY1_rank   R-squared:                       0.195\n",
                        "Model:                            OLS   Adj. R-squared:                  0.194\n",
                        "Method:                 Least Squares   F-statistic:                     120.6\n",
                        "Date:                Mon, 20 Oct 2025   Prob (F-statistic):          4.63e-159\n",
                        "Time:                        00:33:41   Log-Likelihood:                -30851.\n",
                        "No. Observations:                3487   AIC:                         6.172e+04\n",
                        "Df Residuals:                    3479   BIC:                         6.177e+04\n",
                        "Df Model:                           7                                         \n",
                        "Covariance Type:            nonrobust                                         \n",
                        "================================================================================\n",
                        "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "--------------------------------------------------------------------------------\n",
                        "const         3721.3127     28.536    130.406      0.000    3665.363    3777.262\n",
                        "AGEY1X         416.3192     33.244     12.523      0.000     351.140     481.499\n",
                        "ADSEX4        -256.7842     28.948     -8.871      0.000    -313.541    -200.027\n",
                        "PRVEVY1        150.5865     29.444      5.114      0.000      92.857     208.316\n",
                        "DIABDXY1_M18   121.3536     29.831      4.068      0.000      62.865     179.842\n",
                        "ARTHDXY1       385.3988     32.682     11.792      0.000     321.321     449.477\n",
                        "CHDDXY1         90.5351     34.611      2.616      0.009      22.675     158.395\n",
                        "MIDXY1         135.6869     34.004      3.990      0.000      69.016     202.358\n",
                        "==============================================================================\n",
                        "Omnibus:                      187.994   Durbin-Watson:                   1.861\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.189\n",
                        "Skew:                          -0.154   Prob(JB):                     8.63e-19\n",
                        "Kurtosis:                       2.309   Cond. No.                         2.14\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "def backward_elimination(X, y, significance_level=0.05):\n",
                "    features = X.columns.tolist()\n",
                "    while(len(features) > 0):\n",
                "        features_with_constant = sm.add_constant(X[features])\n",
                "        p_values = sm.OLS(y, features_with_constant).fit().pvalues[1:]\n",
                "        max_p_value = p_values.max()\n",
                "        if(max_p_value >= significance_level):\n",
                "            excluded_feature = p_values.idxmax()\n",
                "            features.remove(excluded_feature)\n",
                "        else:\n",
                "            break \n",
                "    return features\n",
                "    \n",
                "backward_features = backward_elimination(X_scaled, y)\n",
                "print(\"Selected features (Backward Elimination):\", backward_features)\n",
                "    \n",
                "# Fit a model with the selected features\n",
                "model_backward = sm.OLS(y, sm.add_constant(X_scaled[backward_features])).fit()\n",
                "print(model_backward.summary())\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## 3. Principal Component Regression (PCR)\n",
                "PCR is a regression technique that uses the principal components of the predictor variables as the independent variables in a linear regression model.\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PCR R-squared: 0.16537369045171757\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "    # Perform PCA\n",
                "pca = PCA()\n",
                "X_pca = pca.fit_transform(X_scaled)\n",
                "    \n",
                "# Split data\n",
                "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
                "    \n",
                "# Fit a linear regression model on the principal components\n",
                "pcr_model = LinearRegression()\n",
                "pcr_model.fit(X_train_pca, y_train)\n",
                "    \n",
                "# Evaluate the model\n",
                "y_pred_pcr = pcr_model.predict(X_test_pca)\n",
                "print(\"PCR R-squared:\", r2_score(y_test, y_pred_pcr))\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## 4. Partial Least Squares Regression (PLSR)\n",
                "PLSR is similar to PCR, but it creates the components by considering both the predictors and the response variable.\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PLSR R-squared: 0.1653503745735313\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
                "    \n",
                "# Fit a PLS regression model\n",
                "plsr_model = PLSRegression(n_components=5) # n_components can be tuned\n",
                "plsr_model.fit(X_train, y_train)\n",
                "    \n",
                "# Evaluate the model\n",
                "y_pred_plsr = plsr_model.predict(X_test)\n",
                "print(\"PLSR R-squared:\", r2_score(y_test, y_pred_plsr))\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "    ## 5. Conclusion\n",
                "    This notebook provided an overview of advanced regression techniques, including feature selection methods and dimensionality reduction regression.\n",
                "    - **Forward and Backward Selection** helped us identify a subset of the most statistically significant predictors.\n",
                "    - **PCR and PLSR** provide alternative ways to handle multicollinearity and high-dimensional data.\n",
                "    "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
